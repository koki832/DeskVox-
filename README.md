# PRD: DeskVox-自分専用音声入力（OSS・単一マイク）

- バージョン: v0.9
- 最終更新: 2025-08-11
- 作成目的: 騒がしいオフィス等の環境で**自分の声だけ**をリアルタイムに文字起こしするローカルアプリを、**OSSのみ・単一マイク**で提供する。

---

## 1. 概要 / 問題提起

- 多人数が同時に会話するオフィスでは、一般的なSTTは周囲の話者や環境音を拾い、誤認識が増える。
- 指向性や骨伝導などの専用ハードなしでも、**話者選別（自分のみ）****と****ノイズ抑制**を組み合わせれば、実用精度が狙える。
- 本プロダクトは、**ローカル完結**・**OSSのみ**・**単一マイク**という制約下で、実用レベルの遅延と精度を両立させる。

## 2. 目的 / 成功指標 (North Star & KPIs)

- **North Star**: 利用者がノート/チャット/IDEへの音声入力を日常的に代替できる体験。
- **主要KPI（受け入れ基準でも使用）**
  - **WER (文字誤り率)**: 実オフィス 0–10dB SNR で ≤ **12%**（MVPは ≤ 15%）
  - **他人発話透過率**: ≤ **5%**（MVPは ≤ 10%）
  - **確定遅延**: 発話終了→テキスト確定 ≤ **1.0秒**（MVPは ≤ 1.5秒）
  - **安定性**: 8時間連続稼働でクラッシュ/音切れ無し
  - **CPU使用率**: 4C/8Tクラスで平均 ≤ **70%**

## 3. ターゲットユーザー / ペルソナ

- **知的労働者**: 会議メモ、思考ログ、チャット返信を音声で行いたい。
- **開発者/ライター**: キーボード併用で高速入力、手の負担軽減。
- **議事録担当/サポート職**: 近くの雑談やBGMがある環境でも正確に記録したい。

## 4. ユースケース（優先順）

1. 自席での**メモ取り**（思考の独り言）。
2. 周囲が会話する中での**チャット返信**作成。
3. ミーティング中に自分発話だけを**ライブ文字化**（議事録下書き）。
4. コーディング時の**スニペット下書き**作成（IDEへの貼り付け）。

## 5. スコープ / 非スコープ

- **スコープ**
  - ローカル実行（Windows / Linux）。
  - 単一マイク入力、16kHz/mono 推奨。
  - 日本語中心、英語混在を許容。
  - CLI（MVP）、軽量UI（v1以降）。
- **非スコープ**
  - 多マイク配列/ビームフォーミング前提。
  - クラウドAPI依存（オプション化は将来検討）。
  - 完全な音源分離（物理的限界超えは不可）。

## 6. 競合/代替手段の理解（要点）

- 汎用STT（Whisperそのまま）：騒音・他話者に弱い。
- 専用ハード（骨伝導/指向性）：効果大だが費用や装着性に課題。
- 本プロダクトは**ソフトウェアのみ**で実用値に到達する設計を提供。

## 7. UX要件

- **MVP: CLI**
  - `voice-me --start` で開始、`Ctrl+C`で終了。
  - 標準出力/クリップボード/ファイル(JSONL)へ出力選択。
  - ホットキー（開始/一時停止/確定）。
  - ステータス行：VAD状態、しきい値、CPU、遅延の簡易表示。
- **v1: 軽量UI**
  - トレイ常駐、オン/オフ、テキストログ、設定パネル。
  - 音量メータ、しきい値スライダ、モデル変更、プロファイル切替。

## 8. 機能要件（FR）

- **FR-1 入力**: マイクから 16kHz/16bit/mono 連続取得。
- **FR-2 前処理**: RNNoise でノイズ抑制、レベル正規化。
- **FR-3 VAD**: WebRTC VAD（既定）/ Silero VAD（選択式）。
- **FR-4 話者選別（ゲート）**: ECAPA-TDNN で埋め込み作成、類似度しきい値で通過判定。
- **FR-5（拡張）TSE**: VoiceFilter系/TS-VAD/Asteroid による条件付き分離（設定でON）。
- **FR-6 STT**: faster-whisper（CTranslate2, `small`/`medium`）。
- **FR-7 出力**: STDOUT / クリップボード / ファイル(JSONL) / Webhook。
- **FR-8 設定**: YAML/JSON。VAD、しきい値、モデル、言語等。
- **FR-9 プロファイル**: 複数話者プロファイル（自分A/B）。
- **FR-10 ログ**: 処理遅延、CPU/メモリ、透過率試算（推定値）。

## 9. 非機能要件（NFR）

- **性能**: §2のKPIを満たす。
- **信頼性**: 8時間連続稼働、メモリリーク無し。
- **セキュリティ/プライバシー**: デフォルトはローカル処理、音声は保存しない（オプトイン）。
- **可観測性**: ログ/メトリクス/簡易ダッシュ（UI版）。
- **導入性**: `pip install` または Docker で即時利用可。

## 10. ユーザーフロー（MVP: CLI）

1. 初回起動 → **声紋登録ウィザード**（30–60秒×3シーン録音→平均化）。
2. `voice-me --start` 実行 → ステータス表示。
3. 発話 → VAD + ゲート（必要時TSE）→ Whisper → テキスト確定。
4. 出力配送（STDOUT/クリップボード/JSONL/Webhook）。
5. ホットキーで一時停止/再開、`Ctrl+C`で終了。

## 11. システム設計（論理）

```
Mic → RNNoise → VAD →（TSE）→ Speaker Gate → Buffer(発話単位) → Whisper → PostProcess → Output
```

- **PostProcess**: 句読点付与、簡易辞書補正、半角/全角統一。
- **設定**: `config.yaml` をロード、CLI引数で上書き。

## 12. 技術選定（OSS）

- RNNoise, webrtcvad / Silero VAD(ONNX), SpeechBrain(ECAPA-TDNN), pyannote(任意), Asteroid(任意), faster-whisper(CTranslate2)。
- 言語: Python 3.10+。GPU任意（あれば加速）。

## 13. 設定ファイル（例）

```yaml
sample_rate: 16000
vad: { type: webrtc, aggressiveness: 2 }
speaker:
  enroll_path: profiles/me.npy
  threshold: 0.60
  average_multi_scene: true
tse: { enabled: false, model: voicefilter-lite }
stt: { model: small, compute_type: int8, language: ja }
output: { mode: stdout, file: out.jsonl, webhook: null }
ui: { tray: false }
logging: { level: info, file: logs/app.log }
```

## 14. リリース計画

- **MVP (v0.9)**: CLI、RNNoise + VAD + ゲート + Whisper、声紋登録、JSONL/STDOUT/クリップボード、基本ログ。
- **v1.0**: 軽量UI（トレイ）、Webhook、プロファイル複数、簡易辞書補正、設定画面。
- **v1.1**: TSE（ON/OFF）、モデル切替UI、簡易メトリクス表示。

## 15. マイルストーン / 成果物

- **M1 要件確定**（本PRD確定、テスト指標合意）
- **M2 POC①**（軽量版実装・S1–S3評価）
- **M3 チューニング**（しきい値/パラメタ最適化、WER/透過率改善）
- **M4 POC②**（TSE導入・比較実験）
- **M5 v1.0**（UI・配布パッケージ化、ドキュメント）

## 16. 受け入れ基準（Acceptance Criteria）

- **精度**: S1（独話10分, 雑談あり）で WER ≤ 12%（MVP ≤ 15%）。
- **漏れ**: 隣席発話同時割込みテストで透過率 ≤ 5%（MVP ≤ 10%）。
- **遅延**: 1.0秒以内（MVP 1.5秒以内）。
- **安定性**: 30分×3セット連続でエラー/音切れ無し。
- **導入**: README手順のみで新規環境構築≤15分。

## 17. テスト計画（概要）

- **S1**: 独話10分、周囲雑談55–70dBA → WER測定。
- **S2**: 隣席発話の同時割込み（3回/分） → 透過率測定。
- **S3**: 打鍵・空調・BGM混在 → 遅延/CPU/ドロップ測定。
- **回帰**: しきい値 0.55/0.60/0.65 比較表。

## 18. リスクと緩和策

- **単一マイクの物理限界** → TSEの導入、マイク位置/ゲイン最適化ガイド。
- **似声ユーザー誤透過** → 多様な登録音声で平均化、閾値引き上げ、短期アダプテーション。
- **CPU負荷** → `tiny`/`base` 切替、フレーム設計、バッチ化、GPU対応。
- **日本語固有名詞誤変換** → ユーザー辞書/頻出語補正、後処理。

## 19. 分析/ログ要件

- 収集: 処理時間(ms)、バッファ遅延、CPU/メモリ、VAD比率、ゲート通過率、STT信頼度。
- 保存: ローカル（ユーザー選択でJSONL/CSV）。PII除去方針。

## 20. セキュリティ/プライバシー

- 既定でクラウド送信なし。音声保存はオフ。
- ログにテキスト本文を保存する場合はユーザー同意が必要。

## 21. アクセシビリティ/ローカリゼーション

- 表示言語: 日本語（英語UIは将来）。
- 視認性: UI版では高コントラスト/キーボード操作対応。

## 22. 運用/導入ガイド（要求）

- マイクを口元10–15cm、ゲインはクリップ直前。
- VAD厳しさは2→取りこぼし時1。
- Whisperは CPU: `small`、GPU: `medium` を推奨。

## 23. 依存関係/前提

- Python 3.10+、`pip` 環境。
- （任意）GPU: NVIDIA CUDA 11+。

## 24. オープン課題（Open Questions）

- TSEの既定値: 無効で開始か、軽量モデルを既定ONにするか。
- PostProcessの辞書補正の方法（ルール/言語モデル）。
- Webhookペイロードの標準化（他アプリ統合方針）。

---

### 付録A: CLI仕様（案）

```
voice-me start \
  --config ./config.yaml \
  --model small --language ja \
  --vad webrtc --vad-aggr 2 \
  --threshold 0.60 \
  --tse off \
  --out stdout

voice-me enroll --seconds 60 --scenes 3 --out profiles/me.npy
```

### 付録B: 出力JSONL（例）

```json
{"ts_start": 3.12, "ts_end": 5.98, "text": "本日のToDoを記録します", "conf": 0.74}
```

### 付録C: 受け入れテストチェックリスト（抜粋）

-

